---
aliases:
tags: philosophy
---
Link: https://fermatslibrary.com/s/are-you-living-in-a-computer-simulation
pdf: [[simulation.pdf]]
Other: [Elon musk argument](https://www.youtube.com/watch?v=2KK_kzrJPS8&list=PLKof9YSAshgyPqlK-UUYrHfIQaOzFPSL4)

# Are you living in a Computer Simulation?
## ELI5

There are three scenarios that could unfold for humanity:
A) We die before developing very advanced technology.
B) We live enough to develop very advanced technology, but creating a computer simulation of an entire universe is impossible.    
C) We actually simulate an entire universe in the future.
    
If option C is true, that universe could develop sentient life, as our own. If that happens, we have no better chance than our 'sims' of not being in a simulation, therefore, it is exceedingly likely that we are in a simulation.

### Abstract
This paper argues that at least one of the following propositions is true: 
(1) the human species is very likely to go extinct before reaching a “posthuman” stage; 
(2) any posthuman civilization is extremely unlikely to run a significant number of simulations of their evolutionary history (or variations thereof); 
(3) we are almost certainly living in a computer simulation. 
It follows that the belief that there is a significant chance that we will one day become posthumans who run ancestor‐simulations is false, unless we are currently living in a simulation. A number of other consequences of this result are also discussed.

### Introduction
Some forecasts by serious technologists and futurologists predict that enormous amounts of computing power will be available in the future. Let us suppose for a moment that these predictions are correct. One thing that later generations might do with their super‐powerful computers is run detailed simulations of their forebears or of people like their forebears. Because their computers would be so powerful, they could run a great many such simulations. 

Suppose that these simulated people are conscious (as they would be if the simulations were sufficiently fine‐grained and if a certain quite widely accepted position in the philosophy of mind is correct). Then it could be the case that the vast majority of minds like ours do not belong to the original race but rather to people simulated by the advanced descendants of an original race.

Therefore, if we don’t think that we are currently living in a computer simulation, we are not entitled to believe that we will have descendants who will run lots of such simulations of their forebears.

Apart form the interest this thesis may hold for those who are engaged in futuristic speculation, there are also more purely theoretical rewards. The argument provides a stimulus for formulating some methodological and metaphysical questions, and it suggests naturalistic analogies to certain traditional religious conceptions, which some may find amusing or thoughtprovoking.

The structure of the paper is as follows. 
* First, we formulate an assumption that we need to import from the philosophy of mind in order to get the argument started. 
* Second, we consider some empirical reasons for thinking that running vastly many simulations of human minds would be within the capability of a future civilization that has developed many of those technologies that can already be shown to be compatible with known physical laws and engineering constraints.
* Then follows the core of the argument, which makes use of some simple probability theory, and 
* a section providing support for a weak indifference principle that the argument employs. 
* Lastly, we discuss some interpretations of the disjunction, mentioned in the abstract, that forms the conclusion of the simulation argument.

### The assumption of substrate‐independence
A common assumption in the philosophy of mind is that of substrateindependence. The idea is that mental states can supervene on any of a broad class of physical substrates. Provided a system implements the right sort of computational structures and processes, it can be associated with conscious experiences. It is not an essential property of consciousness that it is implemented on carbon‐based biological neural networks inside a cranium: silicon‐based processors inside a computer could in principle do the trick as well.

The argument we shall present does not, however, depend on any very strong version of  functionalism or computationalism. We need only the weaker assumption that it would suffice for the generation of subjective experiences that the computational processes of a human brain are
structurally replicated in suitably fine‐grained detail, such as on the level of individual synapses. This attenuated version of substrate‐independence is quite widely accepted.

Neurotransmitters, nerve growth factors, and other chemicals that are smaller than a synapse clearly play a role in human cognition and learning. The substrate‐independence thesis is not that the effects of these chemicals are small or irrelevant, but rather that they affect subjective experience only via their direct or indirect influence on computational activities. For example, if there can be no difference in subjective experience without there also being a difference in synaptic discharges, then the requisite detail of simulation is at the synaptic level (or higher).

### The technological limits of computation
At our current stage of technological development, we have neither sufficiently powerful hardware nor the requisite software to create conscious minds in computers. But persuasive arguments have been given to the effect that if technological progress continues unabated then these shortcomings will eventually be overcome. Some authors argue that this stage may be only a few decades away.

Ray Kurzweil predicts that by 2029 a personal computer will be 1,000 times more powerful than the human brain.

The simulation argument is time independent. It does not matter that it will take 100 or 100,000 years, all that matters is that we reach the posthuman stage before going extinct.

It is currently hard to be confident in any upper bound on the computing power that may be available to posthuman civilizations. 

We can with much greater confidence establish lower bounds on posthuman computation, by assuming only mechanisms that are already understood.

The amount of computing power needed to emulate a human mind can likewise be roughly estimated.

There are 10^11 neurons in a human brain operate by sending electrical pulses to one another via approximately 10^15 synapses. Assuming 10 impulses/second this suggests that an adult human brain carries out about 10^16 logical operations per second.

Memory seems to be a no more stringent constraint than processing power. Moreover, since the maximum human sensory bandwidth is ~10^8 bits per second, simulating all sensory events incurs a negligible cost compared to simulating the cortical activity.

The remarkable result of Landauer's study was that human beings remembered two bits per second Extrapolating this value over a lifetime (say 80 years), this rate of memorization would produce:

3600×24×365.25×80×2 = 5,049,216,000

which is somewhat over 10^9 bits for the entire lifetime of a human being.

We can therefore use the processing power required to simulate the central nervous system as an estimate of the total computational cost of simulating a human mind.

If the environment is included in the simulation, this will require additional computing power – how much depends on the scope and granularity of the simulation. Simulating the entire universe down to the quantum level is obviously infeasible, unless radically new physics is discovered. But in order to get a realistic simulation of human experience, much less is needed – only whatever is required to ensure that the simulated humans, interacting in normal human ways with their simulated environment, don’t notice any irregularities.

Moreover, a posthuman simulator would have enough computing power to keep track of the detailed belief‐states in all human brains at all times. Therefore, when it saw that a human was about to make an observation of the microscopic world, it could fill in sufficient detail in the simulation in the
appropriate domain on an as‐needed basis. Should any error occur, the director could easily edit the states of any brains that have become aware of an anomaly before it spoils the simulation.

It thus seems plausible that the main computational cost in creating simulations that are indistinguishable from physical reality for human minds in the simulation resides in simulating organic brains down to the neuronal or subneuronal level. While it is not possible to get a very exact estimate of the cost of a realistic simulation of human history, we can use ~10^33 ‐ 10^36 operations as a rough estimate.

Let's assume that:
-   H = 107 billion humans have ever lived
-   L = 50 years as the average human lifetime
-   T = 31,557,600 seconds in a year
-   O = a range of \[10^14, 10^17\] operations in each human brain per second

H×L×T×O≃\[10^33,10^36\]operations

We can conclude that the computing power available to a posthuman civilization is sufficient to run a huge number of ancestor-simulations even it allocates only a minute fraction of its resources to that purpose. We can draw this conclusion even while leaving a substantial margin of error in all our estimates.

### The core of the simulation argument
The basic idea of this paper can be expressed roughly as follows: If there were a substantial chance that our civilization will ever get to the posthuman stage and run many ancestor‐simulations, then how come you are not living in such a simulation?

![[Pasted image 20210409000805.png]]

By inspecting (*) we can then see that at least one of the following three propositions must be true

**(1)** $f_p$≈0⇒

_"The fraction of human-level civilizations that reach a posthuman stage is very close to zero"_

**(2)** $f_I$≈0⇒

_"The fraction of posthuman civilizations that are interested in running ancestor-simulations is very close to zero"_

**(3)** $f_{sim}$≈1⇒

_"The fraction of all people with our kind of experiences that are living in a simulation is very close to one"_

### A bland indifference principle
We can take a further step and conclude that conditional on the truth of (3), one’s credence in the hypothesis that one is in a simulation should be close to unity. More generally, if we knew that a fraction x of all observers with human‐type experiences live in simulations, and we don’t have any information that indicate that our own particular experiences are any more or less likely than other human‐type experiences to have been implemented in vivo rather than in machina, then our credence that we are in a simulation should equal x. This step is sanctioned by a very weak indifference principle.

It should be stressed that the bland indifference principle expressed by (#) prescribes indifference only between hypotheses about which observer you are, when you have no information about which of these observers you are.

Further, one can consider a sequence of possible situations in which an increasing fraction of all people live in simulations: 98%, 99%, 99.9%, 99.9999%, and so on. As one approaches the limiting case in which everybody is in a simulation (from which one can deductively infer that one is in a simulation oneself), it is plausible to require that the credence one assigns to being in a simulation gradually approach the limiting case of complete certainty in a matching manner.

### Interpretation
The possibility represented by proposition (1) is fairly straightforward. If (1) is true, then humankind will almost certainly fail to reach a posthuman level; for virtually no species at our level of development become posthuman, and it is hard to see any justification for thinking that our own species will be especially privileged or protected from future disasters.

* Conditional on (1), we must give a high credence to DOOM, the hypothesis that humankind will go
extinct before reaching a posthuman level.
	* Perhaps the most natural interpretation of (1) is that we are likely to go extinct as a result of the development of some powerful but dangerous technology.
* Proposition (1) doesn’t by itself imply that we are likely to go extinct soon, only that we are unlikely to reach a posthuman stage.
* Another way for (1) to be true is if it is likely that technological civilization will collapse.

In order for (2) to be true, there must be a strong convergence among the courses of advanced civilizations. 
* One can speculate that advanced civilizations all develop along a trajectory that leads to the recognition of an ethical prohibition against running ancestor‐simulations
* Another possible convergence point is that almost all individual posthumans in virtually all posthuman civilizations develop in a direction where they lose their desires to run ancestor‐simulations.

One conclusion that follows from (2) is that posthuman societies will be very different from human societies: they will not contain relatively wealthy independent agents who have the full gamut of
human‐like desires and are free to act on them.

If we are in a simulation (3). Reality may contain many levels.
In some ways, the posthumans running a simulation are like gods in relation to the people inhabiting the simulation.
if nobody can be sure that they are at the basement‐level, then everybody would have to consider the possibility that their actions will be rewarded or punished, based perhaps on moral criteria, by their simulators.
An afterlife would be a real possibility.

In addition to ancestor‐simulations, one may also consider the possibility of more selective simulations that include only a small group of humans or a single individual.

There is also the possibility of simulators abridging certain parts of the mental lives of simulated beings and giving them false memories of the sort of experiences that they would typically have had during the omitted interval.

Properly understood, therefore, the truth of (3) should have no tendency to make us “go crazy” or to prevent us from going about our business and making plans and predictions for tomorrow.

The chief empirical importance of (3) at the current time seems to lie in its role in the tripartite conclusion established above. We may hope that (3) is true since that would decrease the
probability of (1), although if computational constraints make it likely that simulators would terminate a simulation before it reaches a posthuman level, then out best hope would be that (2) is true.

### Conclusion
A technologically mature “posthuman” civilization would have enormous computing power. Based on this empirical fact, the simulation argument shows that at least one of the following propositions is true: (1) The fraction of humanlevel civilizations that reach a posthuman stage is very close to zero; (2) The fraction of posthuman civilizations that are interested in running ancestorsimulations is very close to zero; (3) The fraction of all people with our kind of experiences that are living in a simulation is very close to one. 

If (1) is true, then we will almost certainly go extinct before reaching posthumanity. If (2) is true, then there must be a strong convergence among the courses of advanced civilizations so that virtually none contains any relatively wealthy individuals who desire to run ancestor‐simulations and are free to do so. If (3) is true, then we almost certainly live in a simulation. In the dark forest of our current ignorance, it seems sensible to apportion one’s credence roughly evenly between (1), (2), and (3). 

Unless we are now living in a simulation, our descendants will almost certainly never run an ancestor‐simulation.
