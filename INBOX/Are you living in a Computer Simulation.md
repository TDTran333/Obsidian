---
aliases:
tags: philosophy
---
Link: https://fermatslibrary.com/s/are-you-living-in-a-computer-simulation
pdf: [[simulation.pdf]]
Other: [Elon musk argument](https://www.youtube.com/watch?v=2KK_kzrJPS8&list=PLKof9YSAshgyPqlK-UUYrHfIQaOzFPSL4)

# Are you living in a Computer Simulation?
## ELI5

There are three scenarios that could unfold for humanity:
A) We die before developing very advanced technology.
B) We live enough to develop very advanced technology, but creating a computer simulation of an entire universe is impossible.    
C) We actually simulate an entire universe in the future.
    
If option C is true, that universe could develop sentient life, as our own. If that happens, we have no better chance than our 'sims' of not being in a simulation, therefore, it is exceedingly likely that we are in a simulation.

### Abstract
This paper argues that at least one of the following propositions is true: 
(1) the human species is very likely to go extinct before reaching a “posthuman” stage; 
(2) any posthuman civilization is extremely unlikely to run a significant number of simulations of their evolutionary history (or variations thereof); 
(3) we are almost certainly living in a computer simulation. 
It follows that the belief that there is a significant chance that we will one day become posthumans who run ancestor‐simulations is false, unless we are currently living in a simulation. A number of other consequences of this result are also discussed.

### Introduction
Some forecasts by serious technologists and futurologists predict that enormous amounts of computing power will be available in the future. Let us suppose for a moment that these predictions are correct. One thing that later generations might do with their super‐powerful computers is run detailed simulations of their forebears or of people like their forebears. Because their computers would be so powerful, they could run a great many such simulations. 

Suppose that these simulated people are conscious (as they would be if the simulations were sufficiently fine‐grained and if a certain quite widely accepted position in the philosophy of mind is correct). Then it could be the case that the vast majority of minds like ours do not belong to the original race but rather to people simulated by the advanced descendants of an original race.

Therefore, if we don’t think that we are currently living in a computer simulation, we are not entitled to believe that we will have descendants who will run lots of such simulations of their forebears.

Apart form the interest this thesis may hold for those who are engaged in futuristic speculation, there are also more purely theoretical rewards. The argument provides a stimulus for formulating some methodological and metaphysical questions, and it suggests naturalistic analogies to certain traditional religious conceptions, which some may find amusing or thoughtprovoking.

The structure of the paper is as follows. 
* First, we formulate an assumption that we need to import from the philosophy of mind in order to get the argument started. 
* Second, we consider some empirical reasons for thinking that running vastly many simulations of human minds would be within the capability of a future civilization that has developed many of those technologies that can already be shown to be compatible with known physical laws and engineering constraints.
* Then follows the core of the argument, which makes use of some simple probability theory, and 
* a section providing support for a weak indifference principle that the argument employs. 
* Lastly, we discuss some interpretations of the disjunction, mentioned in the abstract, that forms the conclusion of the simulation argument.

### The assumption of substrate‐independence
A common assumption in the philosophy of mind is that of substrateindependence. The idea is that mental states can supervene on any of a broad class of physical substrates. Provided a system implements the right sort of computational structures and processes, it can be associated with conscious experiences. It is not an essential property of consciousness that it is implemented on carbon‐based biological neural networks inside a cranium: silicon‐based processors inside a computer could in principle do the trick as well.

The argument we shall present does not, however, depend on any very strong version of  functionalism or computationalism. We need only the weaker assumption that it would suffice for the generation of subjective experiences that the computational processes of a human brain are
structurally replicated in suitably fine‐grained detail, such as on the level of individual synapses. This attenuated version of substrate‐independence is quite widely accepted.

Neurotransmitters, nerve growth factors, and other chemicals that are smaller than a synapse clearly play a role in human cognition and learning. The substrate‐independence thesis is not that the effects of these chemicals are small or irrelevant, but rather that they affect subjective experience only via their direct or indirect influence on computational activities. For example, if there can be no difference in subjective experience without there also being a difference in synaptic discharges, then the requisite detail of simulation is at the synaptic level (or higher).

### The technological limits of computation
At our current stage of technological development, we have neither sufficiently powerful hardware nor the requisite software to create conscious minds in computers. But persuasive arguments have been given to the effect that if technological progress continues unabated then these shortcomings will eventually be overcome. Some authors argue that this stage may be only a few decades away.

Ray Kurzweil predicts that by 2029 a personal computer will be 1,000 times more powerful than the human brain.

The simulation argument is time independent. It does not matter that it will take 100 or 100,000 years, all that matters is that we reach the posthuman stage before going extinct.

It is currently hard to be confident in any upper bound on the computing power that may be available to posthuman civilizations. 

We can with much greater confidence establish lower bounds on posthuman computation, by assuming only mechanisms that are already understood.

The amount of computing power needed to emulate a human mind can likewise be roughly estimated.

There are 10^11 neurons in a human brain operate by sending electrical pulses to one another via approximately 10^15 synapses. Assuming 10 impulses/second this suggests that an adult human brain carries out about 10^16 logical operations per second.

Memory seems to be a no more stringent constraint than processing power. Moreover, since the maximum human sensory bandwidth is ~10^8 bits per second, simulating all sensory events incurs a negligible cost compared to simulating the cortical activity.

The remarkable result of Landauer's study was that human beings remembered two bits per second Extrapolating this value over a lifetime (say 80 years), this rate of memorization would produce:

3600×24×365.25×80×2 = 5,049,216,000

which is somewhat over 10^9 bits for the entire lifetime of a human being.

We can therefore use the processing power required to simulate the central nervous system as an estimate of the total computational cost of simulating a human mind.

If the environment is included in the simulation, this will require additional computing power – how much depends on the scope and granularity of the simulation. Simulating the entire universe down to the quantum level is obviously infeasible, unless radically new physics is discovered. But in order to get a realistic simulation of human experience, much less is needed – only whatever is required to ensure that the simulated humans, interacting in normal human ways with their simulated environment, don’t notice any irregularities.

Moreover, a posthuman simulator would have enough computing power to keep track of the detailed belief‐states in all human brains at all times. Therefore, when it saw that a human was about to make an observation of the microscopic world, it could fill in sufficient detail in the simulation in the
appropriate domain on an as‐needed basis. Should any error occur, the director could easily edit the states of any brains that have become aware of an anomaly before it spoils the simulation.

It thus seems plausible that the main computational cost in creating simulations that are indistinguishable from physical reality for human minds in the simulation resides in simulating organic brains down to the neuronal or subneuronal level. While it is not possible to get a very exact estimate of the cost of a realistic simulation of human history, we can use ~10^33 ‐ 10^36 operations as a rough estimate.

Let's assume that:
-   H = 107 billion humans have ever lived
-   L = 50 years as the average human lifetime
-   T = 31,557,600 seconds in a year
-   O = a range of \[10^14, 10^17\] operations in each human brain per second

H×L×T×O≃\[10^33,10^36\]operations

We can conclude that the computing power available to a posthuman civilization is sufficient to run a huge number of ancestor-simulations even it allocates only a minute fraction of its resources to that purpose. We can draw this conclusion even while leaving a substantial margin of error in all our estimates.

### The core of the simulation argument