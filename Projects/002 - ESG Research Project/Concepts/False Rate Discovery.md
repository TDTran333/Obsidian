Link: https://en.wikipedia.org/wiki/False_discovery_rate
Tags: #stats 
See: [[Different Approaches To Control Type I Errors]]

---

#### From wikipedia:
The false discovery rate (FDR) is a method of conceptualizing the rate of type I errors in null hypothesis testing when conducting multiple comparisons. FDR-controlling procedures are designed to control the expected proportion of "discoveries" (rejected null hypotheses) that are false (incorrect rejections of the null). FDR-controlling procedures provide less stringent control of Type I errors compared to familywise error rate (FWER) controlling procedures (such as the Bonferroni correction), which control the probability of at least one Type I error. Thus, FDR-controlling procedures have greater power, at the cost of increased numbers of Type I errors.

Sermpinis, Georgios, Arman Hassanniakalager, Charalampos Stasinakis, and Ioannis Psaradellis. “Technical Analysis and Discrete False Discovery Rate: Evidence from MSCI Indices.” SSRN Electronic Journal, 2018. https://doi.org/10.2139/ssrn.3284621.

> Over the years many studies have tried  to control  the FDR  measure,  some  with  more  incremental  and  others  with  more comprehensive approaches. Nevertheless, the fundamentalidea of identifying as many true rejections as possible without including too many false ones remains the same (Benjamini and Yekutiely, 2001; Storey, 2003; Storey and Tibshirani, 2003; Storey et al.,2004;Liang and Nettleton, 2012; Liang, 2016). In financial applications, Barras et al.(2010) introduced for the first time an FDR approach similar to that of Storey (2003) which focuses on measuring the proportion of false discoveries among mutual funds generating alphas, while trying to identify those displaying significant positive performance.

##### Are there more financial applications?

[[Barras_Scaillet_Wermers_2010_False_Discoveries_in_Mutual_Fund_Performance]]

> Besides its financial interpretation, the FDR also has a natural statistical meaning, as it is the extension of the Type I error (i.e., rejecting the null, H0, when it is correct) from single to multiple hypothesis testing. In the single case, the Type I error is controlled by using the significance level (i.e., the size of the test). In the multiple case, we replace with the FDR, which is a compound Type I error easure. In both cases, we face a similar trade-off: In order to increase power, we have to increase or the FDR, respectively (see the survey of Romano, Shaikh, and Wolf (2008)).
